name: ci

on:
  push: {}
  pull_request: {}

permissions:
  contents: read

env:
  # Stage6: legacy Week4 test suites are disabled by default; enable by
  # setting RUN_PRIORITY4_TESTS to "true" in workflow dispatch when needed.
  RUN_PRIORITY4_TESTS: "false"

jobs:
  lint:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: pip-${{ runner.os }}-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            pip-${{ runner.os }}-

      - name: Install linters
        run: |
          python -m pip install --upgrade pip
          pip install ruff black bandit

      - name: Ruff (lint)
        run: ruff check .

      - name: Black (format check)
        run: black --check .

      - name: Bandit (security check)
        run: |
          bandit -c .bandit \
            -x ".venv,venv,build,dist,migrations,__pycache__,node_modules,.git" \
            -r services/ libs/ bot/ web/ scripts/ tests/ *.py

  compose_sanity:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Create .env from example
        run: cp .env.example .env
      - name: Prepare bot .env
        run: cp bot/.env.example bot/.env
      - name: Docker Compose config
        run: |
          [ -f bot/.env ] || cp bot/.env.example bot/.env
          docker compose config -q

  build:
    runs-on: ubuntu-latest
    needs: precommit
    concurrency:
      group: ci-build-${{ github.ref }}-${{ matrix.svc }}
      cancel-in-progress: true
    strategy:
      fail-fast: false
      matrix:
        svc: ["calc-service", "risk-engine", "doc-service", "embedding-api", "etl-service"]
    steps:
      - uses: actions/checkout@v4
      - uses: docker/setup-qemu-action@v3
      - uses: docker/setup-buildx-action@v3
      - name: Build ${{ matrix.svc }}
        uses: docker/build-push-action@v6
        with:
          context: .
          file: ./services/${{ matrix.svc }}/Dockerfile
          push: false
          cache-from: type=gha
          cache-to: type=gha,mode=max
          provenance: false

  precommit:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"
      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: pip-${{ runner.os }}-${{ hashFiles('.pre-commit-config.yaml', '**/requirements.txt') }}
          restore-keys: |
            pip-${{ runner.os }}-
      - name: Install pre-commit
        run: |
          python -m pip install --upgrade pip
          pip install pre-commit
      - name: Run pre-commit
        run: pre-commit run --all-files

  migrate:
    runs-on: ubuntu-latest
    needs: precommit
    steps:
      - uses: actions/checkout@v4
      - name: Create .env from example
        run: cp .env.example .env
      - name: Prepare bot .env
        run: cp bot/.env.example bot/.env
      - name: Start database
        run: |
          test -f bot/.env || cp bot/.env.example bot/.env
          docker compose up -d db
      - name: Ensure table ownership for migrator
        run: |
          [ -f .env ] || cp .env.example .env
          DB_SUPERUSER=$(grep -m1 '^POSTGRES_USER=' .env | cut -d'=' -f2-)
          DB_SUPERUSER=${DB_SUPERUSER:-postgres}
          DB_NAME=$(grep -m1 '^POSTGRES_DB=' .env | cut -d'=' -f2-)
          DB_NAME=${DB_NAME:-zakupai}

          tables=(subjects trdbuy lots contracts rnu)
          for table in "${tables[@]}"; do
            docker compose exec -T db psql -U "${DB_SUPERUSER}" -d "${DB_NAME}" \
              -c "ALTER TABLE IF EXISTS $table OWNER TO zakupai;" || true
          done
      - name: Apply bootstrap schema
        run: |
          [ -f .env ] || cp .env.example .env
          DB_SUPERUSER=$(grep -m1 '^POSTGRES_USER=' .env | cut -d'=' -f2-)
          DB_SUPERUSER=${DB_SUPERUSER:-postgres}
          DB_NAME=$(grep -m1 '^POSTGRES_DB=' .env | cut -d'=' -f2-)
          DB_NAME=${DB_NAME:-zakupai}

          test -f bot/.env || cp bot/.env.example bot/.env
          timeout 60 bash -c "until docker compose exec db pg_isready -U \"${DB_SUPERUSER}\" >/dev/null 2>&1; do sleep 2; done"
          for script in db/init/*.sql; do
            cat "$script" | docker compose exec -T db psql -U "${DB_SUPERUSER}" -d "${DB_NAME}" -v ON_ERROR_STOP=1 || exit 1
          done
      - name: Wait for database
        run: |
          test -f bot/.env || cp bot/.env.example bot/.env
          timeout 60 bash -c 'until docker compose exec db pg_isready -U zakupai; do sleep 2; done'
      - name: Run migrations
        run: |
          test -f bot/.env || cp bot/.env.example bot/.env
          docker compose run --rm migrator
      - name: Stop containers
        if: always()
        run: docker compose down

  pytest:
    runs-on: ubuntu-latest
    needs: migrate
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"
      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: pip-${{ runner.os }}-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            pip-${{ runner.os }}-
      - name: Install common lib
        run: pip install -e libs/zakupai_common
        if: github.event_name == 'push' || github.event_name == 'pull_request'
      - name: Cache pip dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/pyproject.toml') }}
          restore-keys: ${{ runner.os }}-pip-
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          find services -name requirements.txt -exec pip install -r {} \;
          pip install pytest pytest-timeout pytest-cov ruff black isort bandit
      - name: Run linters
        run: |
          ruff check .
          black --check .
          isort --check-only .
      - name: Run security checks
        run: |
          bandit -c .bandit \
            -x ".venv,venv,build,dist,migrations,__pycache__,node_modules,.git" \
            -r services/ libs/ bot/ web/ scripts/ tests/ *.py
      - name: Run tests
        run: pytest -q --cov=services --cov=libs --cov-report=term --disable-warnings

  deploy:
    runs-on: ubuntu-latest
    needs: [pytest, bandit-scan]
    if: github.ref == 'refs/heads/refactor/common-lib-test' && github.event_name == 'push'
    steps:
      - uses: actions/checkout@v4
      - uses: docker/setup-buildx-action@v3

      - name: Login to DockerHub
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKERHUB_USERNAME }}
          password: ${{ secrets.DOCKERHUB_TOKEN }}

      - name: Build & Push Docker images
        run: |
          docker build -t zakupai/gateway:stage5 -t zakupai/gateway:latest --build-arg TAG=stage5 ./services/gateway
          docker build -t zakupai/etl-service:stage5 -t zakupai/etl-service:latest --build-arg TAG=stage5 ./services/etl-service
          docker build -t zakupai/risk-engine:stage5 -t zakupai/risk-engine:latest --build-arg TAG=stage5 ./services/risk-engine
          docker build -t zakupai/calc-service:stage5 -t zakupai/calc-service:latest --build-arg TAG=stage5 ./services/calc-service
          docker build -t zakupai/embedding-api:stage5 -t zakupai/embedding-api:latest --build-arg TAG=stage5 ./services/embedding-api
          docker build -t zakupai/bot:stage5 -t zakupai/bot:latest --build-arg TAG=stage5 ./bot
          docker push zakupai/gateway:stage5
          docker push zakupai/gateway:latest
          docker push zakupai/etl-service:stage5
          docker push zakupai/etl-service:latest
          docker push zakupai/risk-engine:stage5
          docker push zakupai/risk-engine:latest
          docker push zakupai/calc-service:stage5
          docker push zakupai/calc-service:latest
          docker push zakupai/embedding-api:stage5
          docker push zakupai/embedding-api:latest
          docker push zakupai/bot:stage5
          docker push zakupai/bot:latest

      - name: Setup SSH key
        run: |
          echo "${{ secrets.SSH_PRIVATE_KEY }}" > ${{ runner.temp }}/ssh_key
          chmod 600 ${{ runner.temp }}/ssh_key

      - name: Deploy to staging
        run: |
          ssh -o ConnectTimeout=30 -o StrictHostKeyChecking=no -i ${{ runner.temp }}/ssh_key user@staging "cd /path/to/zakupai && export TAG=stage5 && docker compose -f docker-compose.yml -f docker-compose.override.prod.yml pull && docker compose -f docker-compose.yml -f docker-compose.override.prod.yml up -d --timeout 60"

      - name: Rollback on failure
        if: failure()
        run: |
          ssh -o ConnectTimeout=30 -o StrictHostKeyChecking=no -i ${{ runner.temp }}/ssh_key user@staging "cd /path/to/zakupai && export TAG=stable && docker compose -f docker-compose.yml -f docker-compose.override.prod.yml up -d --timeout 60"

  smoke-matrix:
    runs-on: ubuntu-latest
    needs: [migrate, build]
    strategy:
      matrix:
        service: [calc, risk, doc, emb]
    steps:
      - uses: actions/checkout@v4
      - name: Create .env from example
        run: cp .env.example .env
      - name: Prepare bot .env
        run: cp bot/.env.example bot/.env
      - name: Start db
        run: docker compose up -d db
      - name: Start ${{ matrix.service }} service
        run: |
          case "${{ matrix.service }}" in
            calc) docker compose up -d calc-service ;;
            risk) docker compose up -d risk-engine ;;
            doc) docker compose up -d doc-service ;;
            emb) docker compose up -d embedding-api ;;
          esac
      - name: Wait for service health
        run: |
          case "${{ matrix.service }}" in
            calc) port=8001 ;;
            risk) port=8002 ;;
            doc) port=8003 ;;
            emb) port=8004 ;;
          esac
          timeout 90 bash -c "until curl -fsS http://localhost:$port/health; do sleep 3; done"
      - name: Run smoke test
        run: bash scripts/smoke.sh

  etl-smoke-test:
    runs-on: ubuntu-latest
    needs: migrate
    steps:
      - uses: actions/checkout@v4
      - name: Create .env from example
        run: cp .env.example .env
      - name: Prepare bot .env
        run: cp bot/.env.example bot/.env
      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"
      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: pip-${{ runner.os }}-etl-${{ hashFiles('services/etl-service/requirements.txt') }}
          restore-keys: |
            pip-${{ runner.os }}-etl-
      - name: Start database
        run: docker compose up -d db
      - name: Wait for database
        run: timeout 60 bash -c "until docker compose exec db pg_isready -U zakupai; do sleep 2; done"
      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          cd services/etl-service
          pip install psycopg2-binary python-dotenv
      - name: Run ETL smoke test
        run: |
          cd services/etl-service
          chmod +x smoke_test.sh
          ./smoke_test.sh
        env:
          PGPASSWORD: zakupai
      - name: Upload smoke test logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: etl-smoke-test-logs
          path: |
            services/etl-service/smoke_test.log
            services/etl-service/ocr_loader.log
          retention-days: 7

  etl-upload-test:
    runs-on: ubuntu-latest
    needs: migrate
    steps:
      - uses: actions/checkout@v4
      - name: Create .env from example
        run: cp .env.example .env
      - name: Prepare bot .env
        run: cp bot/.env.example bot/.env
      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"
      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: pip-${{ runner.os }}-etl-${{ hashFiles('services/etl-service/requirements.txt') }}
          restore-keys: |
            pip-${{ runner.os }}-etl-
      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y tesseract-ocr tesseract-ocr-rus tesseract-ocr-eng
      - name: Start database
        run: docker compose up -d db
      - name: Wait for database
        run: timeout 60 bash -c "until docker compose exec db pg_isready -U zakupai; do sleep 2; done"
      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          cd services/etl-service
          pip install -r requirements.txt
      - name: Run Alembic migrations
        run: |
          cd services/etl-service
          python -m alembic upgrade head
        env:
          DATABASE_URL: postgresql://zakupai:zakupai@localhost:5432/zakupai
      - name: Run ETL upload tests (pytest)
        run: |
          cd services/etl-service
          python -m pytest test_upload.py -v
        env:
          DATABASE_URL: postgresql://zakupai:zakupai@localhost:5432/zakupai
      - name: Build ETL service container
        run: |
          cd services/etl-service
          docker build -t zakupai-etl-service .
      - name: Run integration tests
        run: |
          cd services/etl-service
          bash test_etl_upload.sh
      - name: Upload test artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: etl-upload-test-logs
          path: |
            services/etl-service/test_files/
          retention-days: 7

  priority3-integration:
    runs-on: ubuntu-latest
    needs: migrate
    steps:
      - uses: actions/checkout@v4
      - name: Create .env from example
        run: cp .env.example .env
      - name: Prepare bot .env
        run: cp bot/.env.example bot/.env
      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"
      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: pip-${{ runner.os }}-priority3-${{ hashFiles('services/etl-service/requirements.txt', 'services/embedding-api/requirements.txt') }}
          restore-keys: |
            pip-${{ runner.os }}-priority3-
      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y tesseract-ocr tesseract-ocr-rus tesseract-ocr-eng
      - name: Start required services
        run: docker compose up -d db chromadb embedding-api etl-service goszakup-api n8n
      - name: Wait for services to be ready
        run: |
          timeout 90 bash -c "until docker compose exec db pg_isready -U zakupai; do sleep 2; done"
          timeout 90 bash -c "until curl -fsS http://localhost:8010/api/v2/heartbeat 2>/dev/null; do sleep 2; done"
          timeout 90 bash -c "until curl -fsS http://localhost:7010/health 2>/dev/null; do sleep 2; done"
          timeout 90 bash -c "until curl -fsS http://localhost:7011/health 2>/dev/null; do sleep 2; done"
          timeout 90 bash -c "until curl -fsS http://localhost:7005/health 2>/dev/null; do sleep 2; done"
          timeout 90 bash -c "until curl -fsS http://localhost:5678 2>/dev/null; do sleep 2; done"
      - name: Run ETL migrations
        run: make etl-migrate
        env:
          DATABASE_URL: postgresql://zakupai:zakupai@localhost:5432/zakupai
      - name: Run Priority 3 E2E tests
        run: make test-priority3
        env:
          DATABASE_URL: postgresql://zakupai:zakupai@localhost:5432/zakupai
      - name: Upload test artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: priority3-test-logs
          path: |
            services/etl-service/test_files/
            services/etl-service/*.log
          retention-days: 7
      - name: Stop all containers
        if: always()
        run: docker compose down

  web-ui-integration:
    runs-on: ubuntu-latest
    needs: migrate
    steps:
      - uses: actions/checkout@v4
      - name: Create .env from example
        run: cp .env.example .env
      - name: Prepare bot .env
        run: cp bot/.env.example bot/.env
      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"
      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: pip-${{ runner.os }}-web-ui-${{ hashFiles('web/requirements.txt') }}
          restore-keys: |
            pip-${{ runner.os }}-web-ui-
      - name: Start required services for web-ui
        run: docker compose up -d db etl-service
        env:
          GOSZAKUP_TOKEN: ${{ secrets.GOSZAKUP_TOKEN || 'test_token_for_ci' }}
          GOSZAKUP_BASE: https://ows.goszakup.gov.kz
      - name: Wait for services to be ready
        run: |
          timeout 60 bash -c "until docker compose exec db pg_isready -U zakupai; do sleep 2; done"
          timeout 60 bash -c "until curl -fsS http://localhost:7011/health 2>/dev/null; do sleep 2; done"
      - name: Build web-ui service
        run: |
          cd web
          docker build -t zakupai-web-ui .
      - name: Run web-ui service
        run: |
          docker run -d --name zakupai-web-ui-test \
            --network zakupai_zakupai-network \
            -p 8082:8000 \
            -e GOSZAKUP_TOKEN="${{ secrets.GOSZAKUP_TOKEN || 'test_token_for_ci' }}" \
            -e GOSZAKUP_BASE=https://ows.goszakup.gov.kz \
            -e ETL_SERVICE_URL=http://etl-service:8000 \
            zakupai-web-ui
      - name: Wait for web-ui to be ready
        run: |
          timeout 60 bash -c "until curl -fsS http://localhost:8082/health 2>/dev/null; do sleep 2; done"
      - name: Test web-ui endpoints
        run: |
          echo "Testing /health endpoint"
          curl -fsS http://localhost:8082/health | jq '.'

          echo "Testing /lots endpoint"
          response=$(curl -s -w '%{http_code}' http://localhost:8082/lots -o /tmp/lots_response.json)
          if [[ "$response" == "200" ]]; then
            echo "✅ /lots endpoint returned HTTP 200"
            cat /tmp/lots_response.json | jq '.' | head -20
          elif [[ "$response" == "500" ]]; then
            echo "⚠️ /lots endpoint returned HTTP 500 (expected if GOSZAKUP_TOKEN is invalid)"
            cat /tmp/lots_response.json
          else
            echo "❌ /lots endpoint returned HTTP $response"
            cat /tmp/lots_response.json
            exit 1
          fi
      - name: Upload test artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: web-ui-test-logs
          path: |
            /tmp/lots_response.json
          retention-days: 7
      - name: Stop all containers
        if: always()
        run: |
          docker stop zakupai-web-ui-test || true
          docker rm zakupai-web-ui-test || true
          docker compose down

  webui-e2e-test:
    runs-on: ubuntu-latest
    needs: migrate
    steps:
      - uses: actions/checkout@v4
      - name: Create .env from example
        run: cp .env.example .env
      - name: Prepare bot .env
        run: cp bot/.env.example bot/.env
      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"
      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: pip-${{ runner.os }}-webui-${{ hashFiles('web/requirements.txt') }}
          restore-keys: |
            pip-${{ runner.os }}-webui-
      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y jq tesseract-ocr tesseract-ocr-rus tesseract-ocr-eng
      - name: Start required services
        run: docker compose up -d db goszakup-api etl-service chromadb web-ui
        env:
          GOSZAKUP_TOKEN: test_token_for_ci
          GOSZAKUP_BASE: https://ows.goszakup.gov.kz
      - name: Wait for services to be ready
        run: |
          timeout 90 bash -c "until docker compose exec db pg_isready -U zakupai; do sleep 2; done"
          timeout 90 bash -c "until curl -fsS http://localhost:8010/api/v2/heartbeat 2>/dev/null; do sleep 2; done"
          timeout 90 bash -c "until curl -fsS http://localhost:7010/health 2>/dev/null; do sleep 2; done"
          timeout 90 bash -c "until curl -fsS http://localhost:7011/health 2>/dev/null; do sleep 2; done"
          timeout 90 bash -c "until curl -fsS http://localhost:7005/health 2>/dev/null; do sleep 2; done"
          timeout 90 bash -c "until curl -fsS http://localhost:8082/health 2>/dev/null; do sleep 2; done"
      - name: Check and create test fixture if missing
        run: |
          if [ ! -f web/test_fixtures/scan1.pdf ]; then
            echo "Creating dummy PDF fixture with Cyrillic content..."
            mkdir -p web/test_fixtures
            python3 -c "
            from reportlab.pdfgen import canvas
            import io
            pdf_buffer = io.BytesIO()
            c = canvas.Canvas(pdf_buffer)
            c.drawString(100, 750, 'Тестовый документ для OCR')
            c.drawString(100, 720, 'Содержит информацию об иске о закупке лака')
            c.drawString(100, 690, 'Для тестирования поиска по ключевому слову \"иск\"')
            c.showPage()
            c.save()
            with open('web/test_fixtures/scan1.pdf', 'wb') as f:
                f.write(pdf_buffer.getvalue())
            "
          else
            echo "Test fixture scan1.pdf already exists"
          fi
        env:
          PYTHONPATH: .
      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          cd web
          pip install -r requirements.txt
          pip install pytest pytest-timeout pytest-asyncio httpx reportlab
      - name: Run ETL migrations
        run: make etl-migrate
        env:
          DATABASE_URL: postgresql://zakupai:zakupai@localhost:5432/zakupai
      - name: Run Web UI E2E tests
        run: make webui-test
        env:
          DATABASE_URL: postgresql://zakupai:zakupai@localhost:5432/zakupai
      - name: Save test results
        if: always()
        run: |
          mkdir -p test_results
          if [ -f web/test_results.xml ]; then
            cp web/test_results.xml test_results/
          fi
          docker compose logs web-ui > test_results/webui.log 2>&1 || true
          docker compose logs etl-service > test_results/etl.log 2>&1 || true
      - name: Upload test artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: webui-e2e-test-results
          path: |
            test_results/
            web/test_fixtures/
          retention-days: 7
      - name: Stop all containers
        if: always()
        run: docker compose down

  bandit-scan:
    runs-on: ubuntu-latest
    permissions:
      security-events: write
      contents: read
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"
      - name: Install bandit
        run: pip install bandit[sarif]
      - name: Run bandit (SARIF)
        # Continue on error to not block pipeline, security findings visible in Security tab
        continue-on-error: true
        run: |
          bandit -c .bandit \
            -x ".venv,venv,build,dist,migrations,__pycache__,node_modules,.git" \
            -r services/ libs/ bot/ web/ scripts/ tests/ *.py \
            --severity-level medium \
            -f sarif -o bandit.sarif
      - name: Upload SARIF to GitHub Security
        uses: github/codeql-action/upload-sarif@v3
        if: always()
        with:
          sarif_file: bandit.sarif
          category: bandit-security-scan
      - name: Upload SARIF artifact
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: bandit-sarif-report
          path: bandit.sarif
          retention-days: 30

  # Week 4.1: Integration tests for Web UI enhancements
  # Legacy Week4 integration suite (opt-in via RUN_PRIORITY4_TESTS)
  priority4-integration:
    if: ${{ env.RUN_PRIORITY4_TESTS == 'true' }}
    runs-on: ubuntu-latest
    continue-on-error: false
    env:
      DATABASE_URL: "postgresql://zakupai:test123@localhost:5432/zakupai_test"
    strategy:
      matrix:
        python-version: ["3.11", "3.12"]
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_DB: zakupai_test
          POSTGRES_USER: zakupai
          POSTGRES_PASSWORD: test123
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

      redis:
        image: redis:7-alpine
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379

      chromadb:
        image: ghcr.io/chroma-core/chroma:latest
        env:
          CHROMA_SERVER_HOST: 0.0.0.0
        ports:
          - 8000:8000

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}

      - name: Cache pip dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: pip-${{ runner.os }}-${{ matrix.python-version }}-${{ hashFiles('**/requirements*.txt') }}
          restore-keys: |
            pip-${{ runner.os }}-${{ matrix.python-version }}-
            pip-${{ runner.os }}-

      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y curl jq postgresql-client redis-tools

      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install fastapi uvicorn[standard] sqlalchemy psycopg2-binary jinja2
          pip install redis pandas chromadb httpx structlog pydantic apscheduler prometheus-fastapi-instrumentator
          pip install pytest pytest-timeout pytest-asyncio pytest-mock requests responses python-docx
          pip install python-telegram-bot aiohttp reportlab python-multipart

      - name: Set up test environment
        run: |
          # Wait for services to be ready
          sleep 10

          # Test database connection
          PGPASSWORD=test123 psql -h localhost -U zakupai -d zakupai_test -c "SELECT version();"

          # Test Redis connection
          redis-cli -h localhost ping

      - name: Run database migrations
        run: |
          # Apply all migrations including Week 4.1
          export DATABASE_URL="postgresql://zakupai:test123@localhost:5432/zakupai_test"

          # Run basic schema setup (mock)
          python -c "
          from sqlalchemy import create_engine, text
          import os

          engine = create_engine(os.getenv('DATABASE_URL'))
          with engine.connect() as conn:
              # Basic tables for testing
              conn.execute(text('''
                  CREATE TABLE IF NOT EXISTS lots (
                      id BIGSERIAL PRIMARY KEY,
                      nameRu TEXT,
                      amount NUMERIC(20,2),
                      lastUpdateDate TIMESTAMP,
                      trdBuyId BIGINT
                  );

                  CREATE TABLE IF NOT EXISTS trdbuy (
                      id BIGSERIAL PRIMARY KEY,
                      customerNameRu TEXT,
                      refBuyStatusId INT
                  );

                  CREATE TABLE IF NOT EXISTS prices (
                      id BIGSERIAL PRIMARY KEY,
                      product_name TEXT NOT NULL,
                      amount NUMERIC(20,2) NOT NULL CHECK (amount >= 0),
                      supplier_bin VARCHAR(12) NOT NULL,
                      imported_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
                  );

                  CREATE TABLE IF NOT EXISTS import_logs (
                      id BIGSERIAL PRIMARY KEY,
                      file_name VARCHAR(255) NOT NULL,
                      status VARCHAR(20) NOT NULL,
                      total_rows INTEGER NOT NULL DEFAULT 0,
                      success_rows INTEGER NOT NULL DEFAULT 0,
                      error_rows INTEGER NOT NULL DEFAULT 0,
                      error_details JSONB,
                      processing_time_ms INTEGER,
                      imported_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
                  );
              '''))
              conn.commit()
          print('Test database setup complete')
          "

      - name: Run Week 4.1 E2E Tests
        env:
          DATABASE_URL: "postgresql://zakupai:test123@localhost:5432/zakupai_test"
          REDIS_URL: "redis://localhost:6379/0"
          CHROMADB_URL: "http://localhost:8000"
          FLOWISE_API_URL: "http://mock-flowise:3000"
        run: |
          # Run specific Week 4.1 tests
          python -m pytest tests/test_e2e_week4.py -v --tb=short
          python -m pytest tests/test_import_prices.py -v --tb=short
          python -m pytest tests/test_lot_summary.py -v --tb=short

      - name: Start Web UI service for smoke tests
        env:
          DATABASE_URL: "postgresql://zakupai:test123@localhost:5432/zakupai_test"
          REDIS_URL: "redis://localhost:6379/0"
          CHROMADB_URL: "http://localhost:8000"
        run: |
          # Start web service in background
          cd web
          python main.py &
          WEB_PID=$!
          echo $WEB_PID > /tmp/web.pid

          # Wait for service to start
          sleep 5

          # Basic health check
          timeout 30 bash -c 'until curl -f http://localhost:8000/health 2>/dev/null; do sleep 1; done'

      - name: Run Smoke Tests
        env:
          BASE_URL: "http://localhost:8000"
          RISK_ENGINE_URL: "http://localhost:8001"  # Will fail gracefully
          TIMEOUT: "10"
        run: |
          # Run smoke tests
          ./scripts/smoke_tests.sh || echo "Some smoke tests failed (expected in CI)"

      - name: Cleanup
        if: always()
        run: |
          # Kill background processes
          if [ -f /tmp/web.pid ]; then
            kill $(cat /tmp/web.pid) 2>/dev/null || true
          fi

      - name: Test Results Summary
        if: always()
        run: |
          echo "Week 4.1 Integration Tests Summary:"
          echo "- Python version: ${{ matrix.python-version }}"
          echo "- Tests completed: $(date)"
          echo "- Check individual steps for detailed results"

  # Week 4.2: Performance testing with Locust
  # Legacy Week4 performance suite (opt-in via RUN_PRIORITY4_TESTS)
  priority4-performance:
    if: ${{ env.RUN_PRIORITY4_TESTS == 'true' }}
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ["3.11", "3.12"]
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_DB: zakupai_test
          POSTGRES_USER: zakupai
          POSTGRES_PASSWORD: test123
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

      redis:
        image: redis:7-alpine
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379

      flowise:
        image: flowiseai/flowise:latest
        env:
          FLOWISE_USERNAME: admin
          FLOWISE_PASSWORD: test123
        ports:
          - 3000:3000

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}

      - name: Cache pip dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: pip-${{ runner.os }}-${{ matrix.python-version }}-performance-${{ hashFiles('**/requirements*.txt') }}
          restore-keys: |
            pip-${{ runner.os }}-${{ matrix.python-version }}-performance-
            pip-${{ runner.os }}-${{ matrix.python-version }}-
            pip-${{ runner.os }}-

      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y curl jq postgresql-client redis-tools

      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install fastapi uvicorn[standard] sqlalchemy psycopg2-binary jinja2
          pip install redis pandas httpx structlog pydantic python-multipart apscheduler prometheus-fastapi-instrumentator
          pip install reportlab python-docx aiofiles
          pip install locust pytest pytest-timeout pytest-asyncio responses
          pip install prometheus-client

      - name: Set up test environment
        run: |
          # Wait for services to be ready
          sleep 15

          # Test database connection
          PGPASSWORD=test123 psql -h localhost -U zakupai -d zakupai_test -c "SELECT version();"

          # Test Redis connection
          redis-cli -h localhost ping

          # Test Flowise connection (with retries)
          timeout 60 bash -c 'until curl -f http://localhost:3000 2>/dev/null; do sleep 2; done' || echo "Flowise may not be ready, proceeding anyway"

      - name: Setup test database
        env:
          DATABASE_URL: "postgresql://zakupai:test123@localhost:5432/zakupai_test"
        run: |
          # Run all database migrations including Week 4.2
          python -c "
          from sqlalchemy import create_engine, text
          import os

          engine = create_engine(os.getenv('DATABASE_URL'))
          with engine.connect() as conn:
              # Apply Week 4.2 schema
              conn.execute(text('''
                  -- Basic tables
                  CREATE TABLE IF NOT EXISTS lots (
                      id BIGSERIAL PRIMARY KEY,
                      nameRu TEXT,
                      amount NUMERIC(20,2),
                      lastUpdateDate TIMESTAMP,
                      trdBuyId BIGINT
                  );

                  CREATE TABLE IF NOT EXISTS trdbuy (
                      id BIGSERIAL PRIMARY KEY,
                      customerNameRu TEXT,
                      refBuyStatusId INT
                  );

                  -- Week 4.2: Supplier sources
                  CREATE TABLE IF NOT EXISTS supplier_sources (
                      id SERIAL PRIMARY KEY,
                      name VARCHAR(50) NOT NULL UNIQUE,
                      url_template VARCHAR(255) NOT NULL,
                      parser_type VARCHAR(20) NOT NULL CHECK (parser_type IN ('api', 'web_search', 'mock')),
                      auth_type VARCHAR(10) NOT NULL CHECK (auth_type IN ('NONE', 'API_KEY', 'MCP')),
                      credentials_ref VARCHAR(100),
                      rate_limit INTEGER DEFAULT 100,
                      fallback_type VARCHAR(20) DEFAULT 'web_search',
                      active BOOLEAN DEFAULT true
                  );

                  -- Week 4.2: Complaints
                  CREATE TABLE IF NOT EXISTS complaints (
                      id BIGSERIAL PRIMARY KEY,
                      lot_id BIGINT NOT NULL,
                      complaint_text TEXT NOT NULL,
                      reason VARCHAR(255),
                      complaint_date DATE NOT NULL,
                      source VARCHAR(20) NOT NULL DEFAULT 'flowise',
                      format_type VARCHAR(10) DEFAULT 'text',
                      created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
                  );

                  -- Week 4.2: Suppliers cache
                  CREATE TABLE IF NOT EXISTS suppliers_cache (
                      id BIGSERIAL PRIMARY KEY,
                      cache_key VARCHAR(255) NOT NULL UNIQUE,
                      suppliers_data JSONB NOT NULL,
                      sources_used TEXT[],
                      total_results INTEGER DEFAULT 0,
                      created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
                      expires_at TIMESTAMP WITH TIME ZONE NOT NULL
                  );

                  -- Insert default supplier sources
                  INSERT INTO supplier_sources (name, url_template, parser_type, auth_type, rate_limit) VALUES
                  ('satu', 'https://satu.kz/search?q={query}', 'web_search', 'NONE', 60),
                  ('1688', 'https://s.1688.com/selloffer/offer_search.htm?keywords={query}', 'api', 'API_KEY', 100),
                  ('alibaba', 'https://www.alibaba.com/trade/search?SearchText={query}', 'api', 'API_KEY', 100)
                  ON CONFLICT (name) DO NOTHING;

                  -- Insert test lots
                  INSERT INTO lots (id, nameRu, amount, lastUpdateDate) VALUES
                  (12345, 'Тестовая закупка мебели', 500000.00, NOW()),
                  (23456, 'Компьютерное оборудование', 750000.00, NOW()),
                  (34567, 'Канцелярские товары', 125000.00, NOW())
                  ON CONFLICT (id) DO NOTHING;
              '''))
              conn.commit()
          print('Week 4.2 test database setup complete')
          "

      - name: Start test server
        env:
          DATABASE_URL: "postgresql://zakupai:test123@localhost:5432/zakupai_test"
          REDIS_URL: "redis://localhost:6379/0"
          FLOWISE_API_URL: "http://localhost:3000"
        run: |
          # Start web service in background for performance testing
          cd web
          python main.py &
          WEB_PID=$!
          echo $WEB_PID > /tmp/web.pid

          # Wait for service to start
          sleep 10

          # Health check with retries
          timeout 60 bash -c 'until curl -f http://localhost:8000/health 2>/dev/null; do sleep 2; done'

          echo "Web service started successfully on port 8000"

      - name: Run Week 4.2 Unit Tests
        env:
          DATABASE_URL: "postgresql://zakupai:test123@localhost:5432/zakupai_test"
          REDIS_URL: "redis://localhost:6379/0"
          FLOWISE_API_URL: "http://localhost:3000"
        run: |
          # Run Week 4.2 feature tests
          python -m pytest tests/test_flowise_week4_2.py -v --tb=short

      - name: Run Advanced Search Tests
        env:
          BASE_URL: "http://localhost:8000"
        run: |
          # Run advanced search tests
          python -m pytest tests/test_advanced_search.py -v --tb=short

      - name: Run Locust Performance Tests
        env:
          BASE_URL: "http://localhost:8000"
          DATABASE_URL: "postgresql://zakupai:test123@localhost:5432/zakupai_test"
        run: |
          # Run Locust performance tests for 2 minutes
          cd tests

          echo "Starting Locust performance test..."
          locust -f locustfile.py \
            --host=http://localhost:8000 \
            --users=50 \
            --spawn-rate=5 \
            --run-time=2m \
            --headless \
            --html=locust_report.html \
            --csv=locust_stats

          echo "Performance test completed"

      - name: Validate Performance Targets
        run: |
          cd tests
          # Check if performance targets were met
          python -c "
          import csv
          import sys

          try:
              with open('locust_stats_stats.csv', 'r') as f:
                  reader = csv.DictReader(f)
                  stats = list(reader)

              targets_met = 0
              total_targets = 0

              print('Week 4.2 Performance Results:')
              print('=' * 50)

              for row in stats:
                  if row['Type'] == 'GET' or row['Type'] == 'POST':
                      name = row['Name']
                      avg_time = float(row['Average Response Time'])
                      p95_time = float(row['95%'])
                      failure_rate = float(row['Failure Count']) / (float(row['Request Count']) or 1) * 100

                      print(f'Endpoint: {name}')
                      print(f'  Avg response time: {avg_time:.0f}ms')
                      print(f'  95th percentile: {p95_time:.0f}ms')
                      print(f'  Failure rate: {failure_rate:.1f}%')

                      # Check specific targets
                      if 'complaint' in name.lower():
                          total_targets += 1
                          if p95_time < 1000:  # <1 second
                              targets_met += 1
                              print(f'  ✅ Complaint target met (<1s)')
                          else:
                              print(f'  ❌ Complaint target missed (>1s)')

                      elif 'supplier' in name.lower():
                          total_targets += 1
                          if p95_time < 1000:  # <1 second
                              targets_met += 1
                              print(f'  ✅ Supplier target met (<1s)')
                          else:
                              print(f'  ❌ Supplier target missed (>1s)')

                      elif 'autocomplete' in name.lower():
                          total_targets += 1
                          if p95_time < 500:  # <500ms
                              targets_met += 1
                              print(f'  ✅ Autocomplete target met (<500ms)')
                          else:
                              print(f'  ❌ Autocomplete target missed (>500ms)')

                      print()

              print(f'Performance Summary: {targets_met}/{total_targets} targets met')

              if targets_met == total_targets and total_targets > 0:
                  print('🎉 All performance targets achieved!')
                  sys.exit(0)
              elif targets_met >= total_targets * 0.8:
                  print('⚠️  Most performance targets met (80%+)')
                  sys.exit(0)
              else:
                  print('❌ Performance targets not met')
                  sys.exit(1)

          except Exception as e:
              print(f'Error analyzing performance results: {e}')
              print('Performance validation skipped (test data may be incomplete)')
              sys.exit(0)
          "

      - name: Upload performance test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: performance-test-results-python-${{ matrix.python-version }}
          path: |
            tests/locust_report.html
            tests/locust_stats*.csv
          retention-days: 14

      - name: Cleanup
        if: always()
        run: |
          # Kill background processes
          if [ -f /tmp/web.pid ]; then
            kill $(cat /tmp/web.pid) 2>/dev/null || true
          fi

      - name: Performance Test Summary
        if: always()
        run: |
          echo "Week 4.2 Performance Test Summary:"
          echo "- Python version: ${{ matrix.python-version }}"
          echo "- Test duration: 2 minutes"
          echo "- Target users: 50 concurrent"
          echo "- Performance targets:"
          echo "  * Complaint generation: <1 second P95"
          echo "  * Supplier search: <1 second P95"
          echo "  * Autocomplete: <500ms P95"
          echo "- Results uploaded as artifacts"
          echo "- Tests completed: $(date)"
