# ZakupAI Web UI API - Week 4.1 Documentation

Web UI API enhancements for CSV import, lot TL;DR analysis, and autocomplete functionality.

## Overview

Week 4.1 introduces powerful Web UI capabilities:

- **CSV Import**: Stream processing with WebSocket progress tracking
- **Lot TL;DR**: AI-powered summaries with Redis caching
- **Enhanced Autocomplete**: ChromaDB + SQL fallback with Cyrillic support
- **Performance Optimized**: \<5s CSV import, \<1s TL;DR, \<500ms autocomplete

## Base URL

```
http://localhost:8000
```

______________________________________________________________________

## CSV Import API

### Upload Prices CSV

**Endpoint**: `POST /web-ui/import-prices`

Import prices from CSV file with real-time progress tracking via WebSocket.

#### Request

```http
POST /web-ui/import-prices
Content-Type: multipart/form-data

file: test.csv (CSV file ≤5MB)
client_id: unique_client_id
```

#### CSV Format Requirements

```csv
product_name,amount,supplier_bin
Компьютер ASUS,150000.50,123456789012
Принтер HP LaserJet,75000.00,234567890123
Бумага офисная А4,2500.25,345678901234
```

**Validation Rules:**

- `product_name`: Required, non-empty string (UTF-8 supported)
- `amount`: Required, numeric ≥ 0
- `supplier_bin`: Required, exactly 12 digits

#### Response

```json
{
  "import_log_id": 15,
  "status": "SUCCESS",
  "total_rows": 1500,
  "success_rows": 1450,
  "error_rows": 50,
  "processing_time_ms": 3200,
  "errors": [
    {
      "row": 157,
      "error": "amount must be >= 0",
      "data": {"product_name": "Invalid", "amount": -100, "supplier_bin": "123456789012"}
    }
  ]
}
```

#### Status Values

- `SUCCESS`: All rows processed successfully
- `PARTIAL`: Some rows had errors
- `FAILED`: Critical failure, no rows processed
- `PROCESSING`: Import in progress

#### Error Handling

| Status Code | Description                                        |
| ----------- | -------------------------------------------------- |
| 200         | Success or partial success                         |
| 400         | Invalid file format, size >5MB, or missing columns |
| 500         | Internal processing error                          |

### WebSocket Progress Updates

**Endpoint**: `WebSocket /ws/import/{client_id}`

Real-time progress updates during CSV processing.

#### Progress Message Format

```json
{
  "progress": 67.5,
  "rows_ok": 1012,
  "rows_error": 23,
  "current_row": 1035,
  "message": "Processing chunk 2..."
}
```

### Get Import Status

**Endpoint**: `GET /web-ui/import-status/{log_id}`

Retrieve import operation status and details.

#### Response

```json
{
  "id": 15,
  "file_name": "prices_2024.csv",
  "status": "SUCCESS",
  "total_rows": 1500,
  "success_rows": 1450,
  "error_rows": 50,
  "error_details": [
    {"row": 157, "error": "Negative amount", "data": "..."},
    {"row": 892, "error": "Invalid BIN format", "data": "..."}
  ],
  "processing_time_ms": 3200,
  "imported_at": "2024-09-18T10:30:45Z"
}
```

______________________________________________________________________

## Lot TL;DR Analysis

### Get Lot Summary

**Endpoint**: `GET /web-ui/lot/{lot_id}`

Generate AI-powered lot summary with Redis caching and Flowise integration.

#### Request

```http
GET /web-ui/lot/12345
```

#### Response

```json
{
  "lot_id": 12345,
  "summary": "Лот 12345: Поставка компьютерного оборудования для школ, сумма 2.5 млн тенге, активный статус, заказчик - Управление образования Алматы.",
  "source": "flowise",
  "cached": false,
  "generated_at": "2024-09-18T10:35:20Z"
}
```

#### Summary Sources

| Source     | Description                | Cache TTL           |
| ---------- | -------------------------- | ------------------- |
| `cache`    | Retrieved from Redis cache | 24h                 |
| `flowise`  | Generated by AI (Flowise)  | New, will be cached |
| `fallback` | SQL-based fallback         | Cached              |

#### Performance Targets

- **Cache Hit**: \<100ms response time
- **AI Generation**: \<1 second response time
- **Fallback**: \<500ms response time

#### Error Handling

| Status Code | Description                    |
| ----------- | ------------------------------ |
| 200         | Summary generated successfully |
| 404         | Lot not found                  |
| 500         | Internal processing error      |

______________________________________________________________________

## Enhanced Autocomplete

### Search Suggestions

**Endpoint**: `GET /api/search/autocomplete`

Get search suggestions with ChromaDB vector similarity + SQL fallback.

#### Request

```http
GET /api/search/autocomplete?query=компьют
```

#### Query Requirements

- **Minimum length**: 2 characters
- **Supported**: Cyrillic and Latin letters, spaces
- **Filtered**: Numbers and special characters ignored
- **Normalized**: Lowercase, trimmed

#### Response

```json
{
  "suggestions": [
    "компьютерное оборудование",
    "компьютерные программы",
    "компьютерная техника",
    "компьютеры настольные"
  ]
}
```

#### Data Sources (Priority Order)

1. **ChromaDB**: Vector similarity search (primary)
1. **SQL Fallback**: PostgreSQL ILIKE search (backup)
1. **Redis Cache**: 24h TTL for frequent queries

#### Performance Metrics

- **Target Response Time**: \<500ms
- **Cache Hit Rate**: >80% for common queries
- **Cyrillic Support**: Full UTF-8 compatibility

______________________________________________________________________

## Integration Examples

### React/JavaScript CSV Import

```javascript
// File upload with progress tracking
const uploadCSV = async (file, onProgress) => {
  const clientId = crypto.randomUUID();

  // Setup WebSocket for progress
  const ws = new WebSocket(`ws://localhost:8000/ws/import/${clientId}`);
  ws.onmessage = (event) => {
    const progress = JSON.parse(event.data);
    onProgress(progress);
  };

  // Upload file
  const formData = new FormData();
  formData.append('file', file);
  formData.append('client_id', clientId);

  const response = await fetch('/web-ui/import-prices', {
    method: 'POST',
    body: formData
  });

  return await response.json();
};
```

### Autocomplete Component

```javascript
// Autocomplete with debouncing
const SearchAutocomplete = ({ onSelect }) => {
  const [query, setQuery] = useState('');
  const [suggestions, setSuggestions] = useState([]);

  const debouncedSearch = useMemo(
    () => debounce(async (searchQuery) => {
      if (searchQuery.length >= 2) {
        const response = await fetch(
          `/api/search/autocomplete?query=${encodeURIComponent(searchQuery)}`
        );
        const data = await response.json();
        setSuggestions(data.suggestions);
      } else {
        setSuggestions([]);
      }
    }, 300),
    []
  );

  useEffect(() => {
    debouncedSearch(query);
  }, [query, debouncedSearch]);

  return (
    <div className="autocomplete">
      <input
        value={query}
        onChange={(e) => setQuery(e.target.value)}
        placeholder="Поиск товаров..."
      />
      {suggestions.length > 0 && (
        <ul className="suggestions">
          {suggestions.map((suggestion, idx) => (
            <li key={idx} onClick={() => onSelect(suggestion)}>
              {suggestion}
            </li>
          ))}
        </ul>
      )}
    </div>
  );
};
```

### Lot Summary Integration

```javascript
// TL;DR with caching awareness
const LotSummary = ({ lotId }) => {
  const [summary, setSummary] = useState(null);
  const [loading, setLoading] = useState(true);

  useEffect(() => {
    const fetchSummary = async () => {
      try {
        const response = await fetch(`/web-ui/lot/${lotId}`);
        const data = await response.json();
        setSummary(data);
      } catch (error) {
        console.error('Failed to load summary:', error);
      } finally {
        setLoading(false);
      }
    };

    fetchSummary();
  }, [lotId]);

  if (loading) return <div>Загрузка сводки...</div>;

  return (
    <div className="lot-summary">
      <div className="summary-content">
        {summary.summary}
      </div>
      <div className="summary-meta">
        <span className="source-badge">{summary.source}</span>
        {summary.cached && <span className="cache-badge">cached</span>}
        <span className="timestamp">
          {new Date(summary.generated_at).toLocaleString('ru')}
        </span>
      </div>
    </div>
  );
};
```

______________________________________________________________________

## Database Schema

### Import Tables

```sql
-- Imported prices data
CREATE TABLE prices (
    id BIGSERIAL PRIMARY KEY,
    product_name TEXT NOT NULL,
    amount NUMERIC(20,2) NOT NULL CHECK (amount >= 0),
    supplier_bin VARCHAR(12) NOT NULL CHECK (supplier_bin ~ '^[0-9]{12}$'),
    imported_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- Import operation logs
CREATE TABLE import_logs (
    id BIGSERIAL PRIMARY KEY,
    file_name VARCHAR(255) NOT NULL,
    status VARCHAR(20) NOT NULL CHECK (status IN ('SUCCESS', 'FAILED', 'PARTIAL', 'PROCESSING')),
    total_rows INTEGER NOT NULL DEFAULT 0,
    success_rows INTEGER NOT NULL DEFAULT 0,
    error_rows INTEGER NOT NULL DEFAULT 0,
    error_details JSONB,
    processing_time_ms INTEGER,
    imported_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);
```

### Performance Indexes

```sql
-- Optimize price lookups
CREATE INDEX idx_prices_product_name ON prices(product_name);
CREATE INDEX idx_prices_supplier_bin ON prices(supplier_bin);
CREATE INDEX idx_prices_imported_at ON prices(imported_at DESC);

-- Optimize import log queries
CREATE INDEX idx_import_logs_status ON import_logs(status);
CREATE INDEX idx_import_logs_imported_at ON import_logs(imported_at DESC);
```

______________________________________________________________________

## Caching Strategy

### Redis Cache Keys

| Pattern                   | Purpose             | TTL |
| ------------------------- | ------------------- | --- |
| `lot_summary:{lot_id}`    | Lot TL;DR summaries | 24h |
| `autocomplete:{md5_hash}` | Search suggestions  | 24h |

### Cache Invalidation

- **Manual**: Admin tools for clearing specific keys
- **Automatic**: TTL-based expiration
- **Fallback**: Graceful degradation when Redis unavailable

______________________________________________________________________

## Error Handling & Monitoring

### Structured Logging

All requests include structured JSON logs with:

```json
{
  "timestamp": "2024-09-18T10:30:45Z",
  "level": "INFO",
  "message": "CSV import completed",
  "request_id": "uuid-123",
  "user_id": "telegram_user_456",
  "processing_time_ms": 3200,
  "success_rows": 1450,
  "error_rows": 50
}
```

### Monitoring Metrics

- **Import Performance**: Processing time, success rate
- **Cache Hit Rates**: Redis usage statistics
- **API Response Times**: P95, P99 latencies
- **Error Rates**: 4xx/5xx response tracking

### Health Checks

```bash
# Service health
curl http://localhost:8000/health

# Database connectivity
curl http://localhost:8000/health/db

# Redis connectivity
curl http://localhost:8000/health/redis
```

______________________________________________________________________

## Testing

### Unit Tests

```bash
# CSV import tests
python -m pytest tests/test_import_prices.py -v

# Lot summary tests
python -m pytest tests/test_lot_summary.py -v

# E2E integration tests
python -m pytest tests/test_e2e_week4.py -v
```

### Smoke Tests

```bash
# Full smoke test suite
./scripts/smoke_tests.sh

# Specific endpoint tests
BASE_URL=http://localhost:8000 ./scripts/smoke_tests.sh
```

### Performance Tests

```bash
# Load testing with Locust
locust -f tests/locust_performance.py --host=http://localhost:8000
```

______________________________________________________________________

## Security Considerations

### Input Validation

- **File Size**: 5MB limit enforced
- **File Type**: CSV extension validation
- **Content Validation**: Schema and data type checking
- **SQL Injection**: Parameterized queries only
- **XSS Prevention**: Input sanitization

### Rate Limiting

- **Import Operations**: 5 per minute per IP
- **Autocomplete**: 100 per minute per IP
- **TL;DR**: 20 per minute per IP

### Access Control

- **API Keys**: Required for import operations
- **CORS**: Configured for allowed origins only
- **Input Sanitization**: All user input validated

______________________________________________________________________

## Deployment Notes

### Environment Variables

```bash
# Required
DATABASE_URL=postgresql://user:pass@host:5432/db
REDIS_URL=redis://host:6379/0

# Optional with defaults
CHROMADB_URL=http://chromadb:8000
FLOWISE_API_URL=http://flowise:3000
MAX_FILE_SIZE_MB=5
IMPORT_CHUNK_SIZE=1000
```

### Docker Compose

```yaml
version: '3.8'
services:
  web-ui:
    build: ./web
    environment:
      - DATABASE_URL=${DATABASE_URL}
      - REDIS_URL=${REDIS_URL}
      - CHROMADB_URL=http://chromadb:8000
    depends_on:
      - postgres
      - redis
      - chromadb
    ports:
      - "8000:8000"
```

This completes the comprehensive API documentation for Week 4.1 ZakupAI Web UI enhancements.
